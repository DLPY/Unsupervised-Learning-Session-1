{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DLPY/Unsupervised-Learning-Session-1/blob/main/Clustering_EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52c63234",
      "metadata": {
        "id": "52c63234"
      },
      "source": [
        "# **Clustering Customers based on Bank Account Data**\n",
        "\n",
        "Detail on Data: https://www.kaggle.com/shrutimechlearn/churn-modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "753a385d",
      "metadata": {
        "id": "753a385d"
      },
      "source": [
        "## **TODO: Download source data from Github**\n",
        "!wget https://github.com/DLPY/Classification_Session_1/blob/815d80d7c1367925bc148cf698738537d7bdc1c0/Churn_Modelling.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade kneed\n",
        "!pip install colorama\n",
        "!wget https://raw.githubusercontent.com/DLPY/Classification_Session_1/main/Churn_Modelling.csv"
      ],
      "metadata": {
        "id": "GbpEYyMPKGfD"
      },
      "id": "GbpEYyMPKGfD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "216821bb",
      "metadata": {
        "id": "216821bb"
      },
      "source": [
        "### **1. Import necessary packages for performing K-Means Clustering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9571271",
      "metadata": {
        "id": "a9571271"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from kneed import KneeLocator\n",
        "from sklearn import metrics\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import pairwise_distances_argmin, silhouette_score\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler,normalize, MinMaxScaler\n",
        "from yellowbrick.cluster import SilhouetteVisualizer\n",
        "from termcolor import colored\n",
        "import missingno as msno \n",
        "import colorama\n",
        "from colorama import Fore, Style  # maakes strings colored\n",
        "from termcolor import colored, cprint\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ce79faf",
      "metadata": {
        "id": "1ce79faf"
      },
      "source": [
        "### **2. Read data from csv file into Pandas dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2cd32fb",
      "metadata": {
        "id": "d2cd32fb"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('Churn_Modelling.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6941c4bb",
      "metadata": {
        "id": "6941c4bb"
      },
      "source": [
        "### **3. Churn Modeling Data Description**\n",
        "This data set contains details of a bank's customers and the target variable is a binary variable reflecting the fact whether the customer left the bank (closed their account) or they continue to be a customer.\n",
        "\n",
        "Here we have 13 feature columns and Exited is a target column.\n",
        "\n",
        "**Row Numbers:** Row Numbers from 1 to 10000.\n",
        "\n",
        "**CustomerId:** Unique Ids for bank customer identification.\n",
        "\n",
        "**Surname:** Customer's last name.\n",
        "\n",
        "**CreditScore:** Credit score of the customer.\n",
        "\n",
        "**Geography:** The country from which the customer belongs(Germany/France/Spain).\n",
        "\n",
        "**Gender:** Male or Female.\n",
        "\n",
        "**Age:** Age of the customer.\n",
        "\n",
        "**Tenure:** Number of years for which the customer has been with the bank.\n",
        "\n",
        "**Balance:** Bank balance of the customer.\n",
        "\n",
        "**NumOfProducts:** Number of bank products the customer is utilising.\n",
        "\n",
        "**HasCrCard:** Binary Flag for whether the customer holds a credit card with the bank or not(0=No, 1=Yes).\n",
        "\n",
        "**IsActiveMember:** Binary Flag for whether the customer is an active member with the bank or not(0=No, 1=Yes).\n",
        "\n",
        "**EstimatedSalary:** Estimated salary of the customer in Euro.\n",
        "\n",
        "**Exited:** Binary flag 1 if the customer closed account with bank and 0 if the customer is retained(0=No, 1=Yes)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Exploratory Data Analysis (EDA)**"
      ],
      "metadata": {
        "id": "gzpSRsb_deMn"
      },
      "id": "gzpSRsb_deMn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Data, Outliers, Multicollinearity, Drop Null Checks"
      ],
      "metadata": {
        "id": "qLRLzLJQdkQR"
      },
      "id": "qLRLzLJQdkQR"
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "\n",
        "def missing(df):\n",
        "    missing_number = df.isnull().sum().sort_values(ascending=False)\n",
        "    missing_percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
        "    missing_values = pd.concat([missing_number, missing_percent], axis=1, keys=['Missing_Number', 'Missing_Percent'])\n",
        "    return missing_values\n",
        "\n",
        "def missing_values(df):\n",
        "    return missing(df)[missing(df)['Missing_Number']>0]\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "def first_look(col):\n",
        "    print(\"column name    : \", col)\n",
        "    print(\"--------------------------------\")\n",
        "    print(\"per_of_nulls   : \", \"%\", round(df[col].isnull().sum()/df.shape[0]*100, 2))\n",
        "    print(\"num_of_nulls   : \", df[col].isnull().sum())\n",
        "    print(\"num_of_uniques : \", df[col].nunique())\n",
        "    print(df[col].value_counts(dropna = False))\n",
        "\n",
        "def first_looking(df):\n",
        "    print(colored(\"Shape:\", attrs=['bold']), df.shape,'\\n',\n",
        "          f\"There is \", df.shape[0], \" observation and \", df.shape[1], \" columns in the dataset.\", '\\n',\n",
        "          colored('-'*79, 'red', attrs=['bold']),\n",
        "          colored(\"\\nInfo:\\n\", attrs=['bold']), sep='')\n",
        "    print(df.info(), '\\n', \n",
        "          colored('-'*79, 'red', attrs=['bold']), sep='')\n",
        "    print(colored(\"Number of Uniques:\\n\", attrs=['bold']), df.nunique(),'\\n',\n",
        "          colored('-'*79, 'red', attrs=['bold']), sep='')\n",
        "    print(colored(\"Missing Values:\\n\", attrs=['bold']), missing_values(df),'\\n', \n",
        "          colored('-'*79, 'red', attrs=['bold']), sep='')\n",
        "    print(colored(\"All Columns:\", attrs=['bold']), list(df.columns),'\\n', \n",
        "          colored('-'*79, 'red', attrs=['bold']), sep='')\n",
        "\n",
        "    df.columns= df.columns.str.lower().str.replace('&', '_').str.replace(' ', '_')\n",
        "\n",
        "    print(colored(\"Columns after rename:\", attrs=['bold']), list(df.columns),'\\n',\n",
        "              colored('-'*79, 'red', attrs=['bold']), sep='')\n",
        "\n",
        "def duplicate_values(df):\n",
        "    duplicate_values = df.duplicated(subset=None, keep='first').sum()\n",
        "    if duplicate_values > 0:\n",
        "        df.drop_duplicates(keep='first', inplace=True)\n",
        "        print(duplicate_values, colored(\"duplicates were dropped\", attrs=['bold']),'\\n',\n",
        "              colored('-'*79, 'red', attrs=['bold']), sep='')\n",
        "    else:\n",
        "        print(colored(\"No duplicates\", attrs=['bold']),'\\n',\n",
        "              colored('-'*79, 'red', attrs=['bold']), sep='')\n",
        "        \n",
        "def drop_columns(df, drop_columns):\n",
        "    if drop_columns !=[]:\n",
        "        df.drop(drop_columns, axis=1, inplace=True)\n",
        "        print(drop_columns, 'were dropped')\n",
        "    else:\n",
        "        print(colored('We will now check the missing values and if necessary drop some columns!!!', attrs=['bold']),'\\n',\n",
        "              colored('-'*79, 'red', attrs=['bold']), sep='')\n",
        "        \n",
        "def drop_null(df, limit):\n",
        "    print('Shape:', df.shape)\n",
        "    for i in df.isnull().sum().index:\n",
        "        if (df.isnull().sum()[i]/df.shape[0]*100)>limit:\n",
        "            print(df.isnull().sum()[i], 'percent of', i ,'null and were dropped')\n",
        "            df.drop(i, axis=1, inplace=True)\n",
        "            print('new shape:', df.shape)\n",
        "        else:\n",
        "            print(df.isnull().sum()[i], '%, percentage of missing values of', i ,'less than limit', limit, '%, so we will keep it.')\n",
        "    print('New shape after missing value control:', df.shape)\n",
        "\n",
        "###############################################################################"
      ],
      "metadata": {
        "id": "4SIK22wJX_J8"
      },
      "id": "4SIK22wJX_J8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### i) Firts Look of Data"
      ],
      "metadata": {
        "id": "3_RfagOjd4r9"
      },
      "id": "3_RfagOjd4r9"
    },
    {
      "cell_type": "code",
      "source": [
        "first_looking(df)"
      ],
      "metadata": {
        "id": "dRX9qDUmXwx3"
      },
      "id": "dRX9qDUmXwx3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ii) Check for Missing Data"
      ],
      "metadata": {
        "id": "c-oLin8Tdwkk"
      },
      "id": "c-oLin8Tdwkk"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(4, 6))\n",
        "\n",
        "sns.displot(data=df.isnull().melt(value_name=\"missing\"),\n",
        "            y=\"variable\",\n",
        "            hue=\"missing\",\n",
        "            multiple=\"fill\",\n",
        "            height=9.25)\n",
        "\n",
        "plt.axvline(0.3, color=\"r\");"
      ],
      "metadata": {
        "id": "7J7DrY64b1Fk"
      },
      "id": "7J7DrY64b1Fk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### iii) Check for Multicollinearity"
      ],
      "metadata": {
        "id": "CadCALJhd8lj"
      },
      "id": "CadCALJhd8lj"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 10))\n",
        "\n",
        "# Getting the Upper Triangle of the co-relation matrix\n",
        "matrix = np.triu(df.corr())\n",
        "\n",
        "# using the upper triangle matrix as mask \n",
        "sns.heatmap(df.corr(), annot=True, cmap = sns.cubehelix_palette(8), mask=matrix)\n",
        "\n",
        "plt.xticks(rotation=45);"
      ],
      "metadata": {
        "id": "I0JueSPwb1Ka"
      },
      "id": "I0JueSPwb1Ka",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp = df.corr()\n",
        "\n",
        "feature =[]\n",
        "collinear=[]\n",
        "\n",
        "for col in df_temp.columns:\n",
        "    for i in df_temp.index:\n",
        "        if (df_temp[col][i]> .85 and df_temp[col][i] < 1) or (df_temp[col][i]< -.85 and df_temp[col][i] > -1) :\n",
        "                feature.append(col)\n",
        "                collinear.append(i)\n",
        "                print(Fore.RED + f\"\\033[1mmulticolinearity alert\\033[0m between {col} - {i}\")\n",
        "        else:\n",
        "            print(f\"For {col} and {i}, there is \\033[1mNO multicollinearity problem\\033[0m\") \n",
        "\n",
        "unique_list = list(set(feature+collinear))\n",
        "\n",
        "print(colored('*'*80, 'cyan', attrs=['bold']))\n",
        "print(\"\\033[1mThe total number of strong corelated features:\\033[0m\", len(unique_list))"
      ],
      "metadata": {
        "id": "2L6fK4nBdUX1"
      },
      "id": "2L6fK4nBdUX1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### iv) Skewness and Kurtosis"
      ],
      "metadata": {
        "id": "SQejr0aFf9mW"
      },
      "id": "SQejr0aFf9mW"
    },
    {
      "cell_type": "code",
      "source": [
        "df_skew_temp = df.skew()\n",
        "df_skew_temp = pd.DataFrame(df_skew_temp, columns=[\"skewness_value\"])\n",
        "df_skew_temp"
      ],
      "metadata": {
        "id": "aMF8Ivszf3xQ"
      },
      "id": "aMF8Ivszf3xQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kurtosis_limit = 2\n",
        "kurtosis_vals = df.kurtosis()\n",
        "kurtosis_cols = kurtosis_vals[abs(kurtosis_vals) > kurtosis_limit].sort_values(ascending=False)\n",
        "kurtosis_cols"
      ],
      "metadata": {
        "id": "4k_AbycAgM8b"
      },
      "id": "4k_AbycAgM8b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "94eb4814",
      "metadata": {
        "id": "94eb4814"
      },
      "source": [
        "### **5. Transformation**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "737d1d98",
      "metadata": {
        "id": "737d1d98"
      },
      "source": [
        "#### Encoding the categorical variables - Change the text into numbers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d78d4223",
      "metadata": {
        "id": "d78d4223"
      },
      "source": [
        "Review the unique values in the Geography column."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d33d40e",
      "metadata": {
        "id": "3d33d40e"
      },
      "source": [
        "Convert the categorical values into numeric categorical labels so that this data can be used for modelling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df5e60d3",
      "metadata": {
        "scrolled": true,
        "id": "df5e60d3"
      },
      "outputs": [],
      "source": [
        "df['countrycode'] = df['geography'].astype('category').cat.codes\n",
        "df['gendercode'] = df['gender'].astype('category').cat.codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6933fe4e",
      "metadata": {
        "scrolled": true,
        "id": "6933fe4e"
      },
      "outputs": [],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08390182",
      "metadata": {
        "id": "08390182"
      },
      "source": [
        "Quick review - columns that are not useful:\n",
        "* **CustomerId** - a unique customer ID number.\n",
        "* **RowNumber** - This is simply a row number of the data.\n",
        "* **Surname** - does not add any strength as a model input.\n",
        "* **Geography** - this has been converted to a numeric value instead of text.\n",
        "* **Gender** - this has been converted to a numeric value instead of text."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "Clustering EDA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}